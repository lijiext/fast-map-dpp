{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 43,
         "metadata": {},
         "outputs": [],
         "source": [
            "import numpy as np, pickle, math, time\n",
            "from itertools import combinations, permutations\n",
            "from scipy import spatial\n",
            "from scipy import stats\n",
            "from tqdm import tqdm\n",
            "from collections import Counter"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "np.set_printoptions(linewidth=400)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 38,
         "metadata": {},
         "outputs": [],
         "source": [
            "with open('../code/qws.pickle', 'rb') as f:\n",
            "    constrains_service = np.asarray(pickle.load(f)).astype(float)\n",
            "    candidates_service = np.asarray(pickle.load(f)).astype(float)\n",
            "    histories = pickle.load(f)\n",
            "    f.close()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def get_shannon_entropies(histories):\n",
            "    indexs = [[np.argmax(i) for i in item] for item in histories]\n",
            "    shannon_entropies = []\n",
            "    for item in indexs:\n",
            "        shannon_entropy = np.abs(sum([count / len(item) * (math.log2(count / len(item))) for count in Counter(item).values()]))\n",
            "        shannon_entropies.append(shannon_entropy)\n",
            "    return np.array(shannon_entropies)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def shannon_Entropy(history):\n",
            "    # 获取用户的香浓熵， Formula(4)\n",
            "    Shannon_Entropy=0\n",
            "    indexs=[]\n",
            "    for i in history:\n",
            "        maxindex=np.argmax(i)\n",
            "        indexs.append(maxindex)\n",
            "    num_Count=Counter(indexs)\n",
            "    important_index=[]\n",
            "    for i in num_Count.values():\n",
            "        important_index.append(i)\n",
            "    fenmu = len(indexs)\n",
            "    for i in important_index:\n",
            "        Shannon_Entropy += -i / fenmu * (math.log2(i / fenmu))\n",
            "\n",
            "    return Shannon_Entropy\n",
            "\n",
            "def get_shannon_entropies_old(histories):\n",
            "    Shannon_Entropys=[]\n",
            "    for i in histories:\n",
            "        Shannon_Entropy=shannon_Entropy(i)\n",
            "        Shannon_Entropys.append(Shannon_Entropy)\n",
            "    return np.asarray(Shannon_Entropys)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "print('get_shannon_entropies_old:', get_shannon_entropies_old(histories), sep='\\n')\n",
            "print('get_shannon_entropies:', get_shannon_entropies(histories), sep='\\n')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "shannon_entropies = get_shannon_entropies(histories)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# 对于用户的每一次调用记录，统计调用中的最大值的索引\n",
            "indexs = [[np.argmax(i) for i in item] for item in histories]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "shannon_entropies = []\n",
            "for item in indexs:\n",
            "    # print('user_invoke_indexs:', item)\n",
            "    # print('count:', Counter(item))\n",
            "    shannon_entropy = -sum([count / len(item) * (math.log2(count / len(item))) for count in Counter(item).values()])\n",
            "    shannon_entropies.append(shannon_entropy)\n",
            "\n",
            "shannon_entropies = np.array(shannon_entropies)   \n",
            "shannon_entropies"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "shannon_entropies"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# 归一化香农熵(用户的多样化参数)\n",
            "fus = lambda shannon_entropies, H0 : np.asarray([(item - np.min(shannon_entropies) + H0) / (np.max(shannon_entropies) - np.min(shannon_entropies) + H0) for item in shannon_entropies])\n",
            "fus(shannon_entropies, 1)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "H0 = 1\n",
            "H_max = np.max(shannon_entropies)\n",
            "H_min = np.min(shannon_entropies)\n",
            "np.asarray([(item - H_min + H0) / (H_max - H_min + H0) for item in shannon_entropies])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# 获取用户历史调用记录的多样性\n",
            "# 计算列表之间的不相似程度\n",
            "def get_similarity(item1, item2, alpha=0.5, dimensions=8):\n",
            "    distance = spatial.distance.euclidean(item1, item2)\n",
            "    tau = stats.kendalltau(item1, item2).correlation\n",
            "    similarity = alpha * (1.0 - distance / np.sqrt(8.0)) + (1.0 - alpha) * tau\n",
            "    return similarity\n",
            "\n",
            "hlist  = histories[0]\n",
            "# for i,j in list(permutations(range(len(hlist)),2)):\n",
            "#     diversity = 1 -  get_similarity(hlist[i], hlist[j])\n",
            "#     # print(i,j )\n",
            "def get_diversity_of_list(hlist, alpha=0.5, dimensions=8):\n",
            "    return 2 / (len(hlist) * (len(hlist) - 1)) * np.sum([1 - get_similarity(hlist[i], hlist[j], alpha, dimensions) for i, j in list(permutations(range(len(hlist)), 2))])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "get_diversity_of_list(histories[0])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 49,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 124750/124750 [00:38<00:00, 3211.96it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "k1 running time: 00:39\n",
                  "k1:\n",
                  "[[0.40759183 0.25196071 0.17969921 ... 0.18091663 0.36154266 0.30451653]\n",
                  " [0.25196071 0.33900687 0.13424029 ... 0.22647468 0.21284397 0.25399976]\n",
                  " [0.17969921 0.13424029 0.15703821 ... 0.14317347 0.16389951 0.1108084 ]\n",
                  " ...\n",
                  " [0.18091663 0.22647468 0.14317347 ... 0.31192459 0.17525553 0.27218717]\n",
                  " [0.36154266 0.21284397 0.16389951 ... 0.17525553 0.4126113  0.35034569]\n",
                  " [0.30451653 0.25399976 0.1108084  ... 0.27218717 0.35034569 0.68161372]]\n",
                  "k2 running time: 01:14\n",
                  "k2:\n",
                  "[[0.40759183 0.25196071 0.17969921 ... 0.18091663 0.36154266 0.30451653]\n",
                  " [0.25196071 0.33900687 0.13424029 ... 0.22647468 0.21284397 0.25399976]\n",
                  " [0.17969921 0.13424029 0.15703821 ... 0.14317347 0.16389951 0.1108084 ]\n",
                  " ...\n",
                  " [0.18091663 0.22647468 0.14317347 ... 0.31192459 0.17525553 0.27218717]\n",
                  " [0.36154266 0.21284397 0.16389951 ... 0.17525553 0.4126113  0.35034569]\n",
                  " [0.30451653 0.25399976 0.1108084  ... 0.27218717 0.35034569 0.68161372]]\n"
               ]
            }
         ],
         "source": [
            "# 计算核矩阵\n",
            "# 计算\n",
            "def get_cosine_similarity(vector1, vector2):\n",
            "    return 0.5 + 0.5 * (1 - spatial.distance.cosine(vector1, vector2))\n",
            "    \n",
            "\n",
            "def get_kernel_matrix(constrains_service, candidate_service, fu, alpha):\n",
            "    similarities  = np.asarray([get_similarity(item, constrains_service) for item in candidate_service])\n",
            "    kernel_matrix = np.diag(np.square(similarities))\n",
            "    for (i, j) in tqdm(list(combinations(range(len(candidate_service)), 2))):\n",
            "        if i == j:\n",
            "            continue\n",
            "        kernel_matrix[i, j] = fu * alpha * similarities[i] * similarities[j] * get_similarity(candidate_service[i], candidate_service[j])\n",
            "        kernel_matrix[j, i] = kernel_matrix[i, j]\n",
            "    return kernel_matrix\n",
            "    \n",
            "def Kmatrix(constraint=None,candidate=None,fu=None,alpha=None):\n",
            "    scores=[]\n",
            "    kernel_matrix=np.random.randn(len(candidate),len(candidate))\n",
            "#     获取每个服务的得分\n",
            "    for i in range(len(candidate)):\n",
            "        score=get_similarity(candidate[i],constraint)\n",
            "        scores.append(score)\n",
            "\n",
            "    #为kernel matrix赋值\n",
            "    for j in range(len(candidate)):\n",
            "        for k in range(len(candidate)):\n",
            "            if(j==k):\n",
            "                kernel_matrix[j][k]=scores[j]*scores[k]\n",
            "            else:\n",
            "                kernel_matrix[j][k] = fu * alpha * scores[j] * scores[k] * get_similarity(candidate[j], candidate[k])\n",
            "    return kernel_matrix\n",
            "\n",
            "t = time.time()\n",
            "k1 = get_kernel_matrix(constrains_service[0], candidates_service[:500,:], 1, 1)\n",
            "print(f'k1 running time: {time.strftime(\"%M:%S\",time.localtime(time.time() - t))}')\n",
            "print('k1:', k1, sep='\\n')\n",
            "\n",
            "t = time.time()\n",
            "k2 = Kmatrix(constrains_service[0], candidates_service[:500,:], 1, 1)\n",
            "print(f'k2 running time: {time.strftime(\"%M:%S\",time.localtime(time.time() - t))}')\n",
            "print('k2:', k2, sep='\\n')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 48,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "00:00\n"
               ]
            }
         ],
         "source": [
            "t = time.time()\n",
            "print(time.strftime('%M:%S',time.localtime(time.time() - t)))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def get_cosine_similarity(vector1, vector2):\n",
            "    return 0.5 + 0.5 * (1 - spatial.distance.cosine(vector1, vector2))\n",
            "\n",
            "def get_cos_similar(v1,v2):\n",
            "    vector_a = np.mat(v1)\n",
            "    vector_b = np.mat(v2)\n",
            "    num = float(vector_a * vector_b.T)\n",
            "    denom = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)\n",
            "    cos = num / denom\n",
            "    sim = 0.5 + 0.5 * cos\n",
            "    return sim"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "v1 = [1 , 2, 3]\n",
            "v2 = [4, 5, 6]\n",
            "print('get_cosine_similarity:', get_cosine_similarity(v1, v2))\n",
            "print('get_cos_similar:', get_cos_similar(v1, v2))"
         ]
      }
   ],
   "source": [
      "for item in indexs:\n",
      "    # print('user_invoke_indexs:', item)\n",
      "    # print('count:', Counter(item))\n",
      "    shannon_entropy = sum([count / len(item) * (math.log2(count / len(item))) for count in Counter(item).values()])\n",
      "    print('se:', shannon_entropy)\n",
      "    "
   ]
}
],
"metadata": {
"interpreter": {
   "hash": "f26cd6e0b5ac18e57192a5a821bea7993ebc578946ba8b6ebe443716728746ce"
},
"kernelspec": {
   "display_name": "Python 3.8.12 ('dpp')",
   "language": "python",
   "name": "python3"
},
"language_info": {
   "codemirror_mode": {
      "name": "ipython",
      "version": 3
   },
   "nbformat": 4,
   "nbformat_minor": 2
}